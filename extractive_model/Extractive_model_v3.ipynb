{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to self: matched DFs using true_df from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\davidsong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='1'>1. Pre-process X_train</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'true_df.csv' does not exist: b'true_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ab037313bccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# true_df.csv can be found in this zip file that I generated for paralelling pre-processing:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# https://drive.google.com/file/d/1yDXjd7seRCp3_YZDHky3utDVtBdIsSYL/view?usp=sharing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_df.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs109b\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs109b\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs109b\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs109b\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs109b\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'true_df.csv' does not exist: b'true_df.csv'"
     ]
    }
   ],
   "source": [
    "# true_df.csv can be found in this zip file that I generated for paralelling pre-processing:\n",
    "# https://drive.google.com/file/d/1yDXjd7seRCp3_YZDHky3utDVtBdIsSYL/view?usp=sharing\n",
    "df = pd.read_csv(\"true_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust df to match the y_train that we pre-processed by batching\n",
    "df_fixed = np.concatenate((df.iloc[900:1900],df.iloc[6000:6500],df.iloc[7000:9000], df.iloc[12000:16000], df.iloc[18000:24000]))\n",
    "df = pd.DataFrame(df_fixed, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='a'>a. Generate vocabulary via tokenization for embeddings</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't need to get embeddings for headnote tokens, because our\n",
    "# RNN will only extract sentences from the opinion body text;\n",
    "# thus, my model never needs to \"read\" the headnotes\n",
    "all_text = df['token_ops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaner removes numbers and punctuation, as they are probably not needed\n",
    "# for the model to evaluate the IMPORTANCE of a sentence (not meaning)\n",
    "\n",
    "def txt_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    \n",
    "    #added line to remove parantheses\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString) # remove '\"'\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    \n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# all_text is all the text, tokenized for generating the vocabulary, which we need for embedding\n",
    "# df_cleaned is the cleaned dataframe with punctuations/numbers removed\n",
    "\n",
    "all_text = []\n",
    "df_cleaned = []\n",
    "\n",
    "for doc in df['token_ops']:\n",
    "    x = doc.replace(\"##SENT##\", \"newsenthere\")\n",
    "    x = txt_cleaner(x)\n",
    "    df_cleaned.append(x)\n",
    "    \n",
    "    x_tok = nltk.tokenize.WordPunctTokenizer().tokenize(x)\n",
    "    all_text.extend(x_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words are all the unique words in our entire training text set\n",
    "# We will use this to generate embedding layer later\n",
    "words = np.unique(all_text)\n",
    "n_words = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Vocab size: {}\".format(n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding at position 0, and 'zzzzzz' because for some reason, it was not in our unique words list\n",
    "word_index = ['_PADDING_'] +  ['zzzzzzz'] + list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests that our word_index works\n",
    "word_index[50595:50605]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='b'>b. Find maximum length of sentences to cap dataset at</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find how long each sentence in our training set is, to see what max_sentence length is.\n",
    "# We need max_sent_len in order to do padding.\n",
    "# We need padding because we will MaxPool our words into sentences, so need consistent sentence length\n",
    "\n",
    "sent_lengths = []\n",
    "for doc in df['token_ops']:\n",
    "    sents_in_doc = doc.split('##SENT##')\n",
    "    sent_lengths.append(len(sents_in_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1878., 2966., 2376., 1896., 1716., 1545.,  845.,  209.,   57.,\n",
       "          12.]),\n",
       " array([  2. ,  23.5,  45. ,  66.5,  88. , 109.5, 131. , 152.5, 174. ,\n",
       "        195.5, 217. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.sort(sent_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9168148148148149"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that 91.7% of our sentences have lengths less than 130 words\n",
    "# So we arbitrarily pick this as our max sentence length\n",
    "# NOTE: I tried longer sentence lengths, but the JupyterHub GPU crashes\n",
    "max_idx = np.argmax(np.sort(sent_lengths) >130)\n",
    "max_idx/13500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "# Set max words per sentence to 130\n",
    "# Use this size for maxpooling layer\n",
    "max_words_in_sent = 130 #max(sent_lengths)\n",
    "print(max_words_in_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for word index (vocabulary)\n",
    "word2idx = dict(zip(word_index, range(n_words+1)))\n",
    "idx2word = dict(zip(range(n_words+1), word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='b'>a. Generate X_train from cleaned data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 182 ms, total: 21.9 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert to numeric using word2idx and add padding\n",
    "X = []\n",
    "for doc in df_cleaned:\n",
    "    sents_in_doc = doc.split('newsenthere')\n",
    "    \n",
    "    mod_doc = []\n",
    "    for sent in sents_in_doc:\n",
    "        mod_sent=[]\n",
    "        x_tokens = nltk.tokenize.WordPunctTokenizer().tokenize(sent)\n",
    "        # Convert tokens in a sentence to index numbers\n",
    "        for token in x_tokens:\n",
    "            mod_sent.append(word2idx[token])\n",
    "        mod_doc.append(mod_sent[:max_words_in_sent])\n",
    "    X.append(pad_sequences(mod_doc, maxlen=max_words_in_sent, padding='post', value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the X_train\n",
    "X_train = []\n",
    "for doc in X:\n",
    "    concat_doc = []\n",
    "    for sent in doc:\n",
    "        concat_doc.extend(sent)\n",
    "    X_train.append(concat_doc)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length, by words: 27820\n"
     ]
    }
   ],
   "source": [
    "# find the max_doc_len\n",
    "doc_lengths = []\n",
    "for doc in X_train:\n",
    "    doc_lengths.append(len(doc))\n",
    "max_doc_len = max(doc_lengths)\n",
    "print(\"Max document length, by words: {}\".format(max_doc_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cap max senteces per doc to 110 sentences * 130 words per sent, cuz above max_length is too large\n",
    "sents_per_doc =110\n",
    "max_doc_len = sents_per_doc*max_words_in_sent\n",
    "max_doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad documents so that they are all the same number of sentences\n",
    "X_tr_final = pad_sequences(X_train, maxlen=max_doc_len, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 14300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>2. Pre-process Y_train labels</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to batching error, only these pre-processed files work\n",
    "# 2000 oracle iterations take 8 hours\n",
    "files=[\"oracle_batch4.txt\", \n",
    "      \"oracle_batch10.txt\", \n",
    "      \"oracle_batch12.txt\", \n",
    "    \"oracle_batch14.txt\",\n",
    "     \"oracle_batch15.txt\", \n",
    "    \"oracle_batch17.txt\",\n",
    "     \"oracle_batch18.txt\", \n",
    "    \"oracle_batch19.txt\"\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds unprocessed y_train (y_unproc) with a tuple of best sentence indices per document\n",
    "# Also builds F1 Rouge-2 scores, calculated during pre-processing\n",
    "# Borrowed from https://stackoverflow.com/questions/6633678/finding-words-after-keyword-in-python\n",
    "y_unproc=[]\n",
    "rouge_scores=[]\n",
    "\n",
    "for file in files:\n",
    "    f = open('./oracle/'+file, \"r\")\n",
    "    for line in f:\n",
    "        y_tup, split, rouge_score = line.partition('\\t')\n",
    "        rouge_score = rouge_score.strip('\\n')\n",
    "        y_unproc.append(y_tup)\n",
    "        rouge_scores.append(rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices of N/A to drop later from x_train and y_train\n",
    "null_y = []\n",
    "for i in range(len(y_unproc)):\n",
    "    if y_unproc[i] == 'None':\n",
    "        null_y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of nulls: 70\n"
     ]
    }
   ],
   "source": [
    "print(\"# of nulls: {}\".format(len(null_y)))\n",
    "\n",
    "# Drop nulls\n",
    "X_tr_final = np.delete(X_tr_final, null_y, axis=0)\n",
    "y_unproc = np.delete(y_unproc, null_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13430,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13430"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set length of our y_train\n",
    "y_len = len(y_unproc)\n",
    "y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This generates the labels for each word in a sentence (binary 0 or 1, 1 being it is a chosen extracted summary sentence)\n",
    "\n",
    "# initialize zeros in the correct y_train shape\n",
    "y_full = np.zeros(shape=(y_len, sents_per_doc))\n",
    "for i in range(y_len):\n",
    "    if y_unproc[i] != 'None':\n",
    "        y_p = y_unproc[i].strip('(),').split(', ')\n",
    "        y_tpl = tuple(map(int, y_p))\n",
    "        for j in y_tpl:\n",
    "            if j < sents_per_doc:\n",
    "                y_full[i][j] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13430, 110)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='3'>3. Small Model</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3a'>a. Build embedding layer</a>\n",
    "Get GloVE word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nlp.stanford.edu/projects/glove/\n",
    "## I used wikipedia 2014+ Gigaword\n",
    "# Extract word vectors\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_doc_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Potentially use weighting to correct over imbalance between 0 and 1 y values\n",
    "\n",
    "#def weighted_bce(y_true, y_pred):\n",
    "#  weights = (y_true * 30.) + 1.\n",
    "#  bce = K.binary_crossentropy(y_true, y_pred)\n",
    "#  weighted_bce = K.mean(bce * weights)\n",
    "#  return weighted_bce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3b'>b. Build RNN-RNN model</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 14300)]           0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 14300, 50)         4053450   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 14300, 100)        30600     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 110, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 110, 100)          45600     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 110, 1)            101       \n",
      "=================================================================\n",
      "Total params: 4,129,751\n",
      "Trainable params: 76,301\n",
      "Non-trainable params: 4,053,450\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# architecture inspired by SummaRunner \n",
    "# https://github.com/hpzhao/SummaRuNNer/blob/master/models/RNN_RNN.py\n",
    "n_units=50\n",
    "optimizer = tf.keras.optimizers.Adam(clipvalue=1.0)\n",
    "#\"adam\"\n",
    "loss = 'binary_crossentropy'#weighted_bce\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "seq_input = Input(shape=(max_doc_len,))\n",
    "embedded_seq = embedding_layer(seq_input)\n",
    "\n",
    "# Word-level GRU\n",
    "x = Bidirectional(tf.keras.layers.GRU(n_units, return_sequences=True))(embedded_seq)\n",
    "\n",
    "# MaxPool combines words into sentences\n",
    "x = tf.keras.layers.MaxPool1D(pool_size = max_words_in_sent, padding='same')(x)\n",
    "\n",
    "# Sentence-level GRU after maxpooling all words in a sentence\n",
    "biGRU2 = Bidirectional(tf.keras.layers.GRU(n_units, return_sequences=True))(x)\n",
    "\n",
    "# Classification at the sentence level\n",
    "## Potential idea for next version: build more complex classifier layers or add attention layer\n",
    "output = TimeDistributed(Dense(units=1, activation='sigmoid'))(biGRU2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=seq_input, outputs=output) \n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics,)# sample_weight_mode = 'temporal')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index at which to build validation set up to\n",
    "val_size = int(X_tr_final.shape[0]*0.1)\n",
    "\n",
    "# Shuffle indices randomly\n",
    "indices = np.arange(X_tr_final.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_tr_final = X_tr_final[indices]\n",
    "y_full = y_full[indices]\n",
    "\n",
    "# Generate Training and validation sets\n",
    "x_train = X_tr_final[val_size:]\n",
    "y_train = y_full[val_size:]\n",
    "x_val = X_tr_final[:val_size]\n",
    "y_val = y_full[:val_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12087 samples, validate on 1343 samples\n",
      "Epoch 1/5\n",
      "12087/12087 [==============================] - 540s 45ms/sample - loss: 0.1525 - accuracy: 0.9652 - val_loss: 0.1068 - val_accuracy: 0.9695\n",
      "Epoch 2/5\n",
      "12087/12087 [==============================] - 520s 43ms/sample - loss: 0.1045 - accuracy: 0.9690 - val_loss: 0.1029 - val_accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "12087/12087 [==============================] - 519s 43ms/sample - loss: 0.1028 - accuracy: 0.9690 - val_loss: 0.1018 - val_accuracy: 0.9694\n",
      "Epoch 4/5\n",
      "12087/12087 [==============================] - 519s 43ms/sample - loss: 0.1020 - accuracy: 0.9690 - val_loss: 0.1011 - val_accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "12087/12087 [==============================] - 520s 43ms/sample - loss: 0.1012 - accuracy: 0.9690 - val_loss: 0.1005 - val_accuracy: 0.9694\n",
      "CPU times: user 33min 22s, sys: 9min 29s, total: 42min 52s\n",
      "Wall time: 43min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "verbose = 1\n",
    "\n",
    "#callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=4)\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=5,#epochs, \n",
    "                    validation_data=(x_val, y_val), verbose=verbose,\n",
    "                    shuffle=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "#model.save_weights(\"{}.h5\".format('extract_model_v3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"extract_model_v3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='4'>4. Predict Summary and Score Summary</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate probability predictions for each sentence in each document\n",
    "y_val_prob = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following the SummaRunner article, we decide on our best sentences, NOT by p>0.5,\n",
    "# because our positive true labels are too sparse. Instead, pick 5 largest probabilities\n",
    "# per document for our 5-sentence summaries.\n",
    "val_best_sents = []\n",
    "for i in range(len(y_val_prob)):\n",
    "    # Get first 5 sentence indices with largest probabilities\n",
    "    best = np.argsort(y_val_prob[i].reshape(-1))[::-1][0:5]\n",
    "    val_best_sents.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds document and loads it for scoring\n",
    "from Document import Document\n",
    "\n",
    "def load_data(src_file, tgt_file):\n",
    "    docs = []\n",
    "    for src_line, tgt_line in zip(src_file, tgt_file):\n",
    "        src_line = src_line.strip()\n",
    "        tgt_line = tgt_line.strip()\n",
    "        #if src_line == \"\" or tgt_line == \"\":\n",
    "        #    docs.append(None)\n",
    "        #    continue\n",
    "        src_sents = src_line.split('##SENT##')\n",
    "        tgt_sents = tgt_line.strip().split('##SENT##')\n",
    "        docs.append(Document(src_sents, tgt_sents))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13430, 5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(null_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls from original imported DF and then select the validation indices\n",
    "val_df = df.drop(null_y).iloc[indices][:val_size]\n",
    "docs = load_data(val_df['token_ops'], val_df['token_heads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4b'>b. Find Rouge Scores</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyRouge.Rouge.Rouge import Rouge\n",
    "\n",
    "rouge = Rouge(use_ngram_buf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-generated summary's Rouge-2 F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pred=[]\n",
    "for comb, document in zip(val_best_sents, docs):\n",
    "    c_string=[]\n",
    "    for idx in comb:\n",
    "        if idx < document.doc_len:\n",
    "            c_string.append(document.doc_sents[idx])\n",
    "    score = rouge.compute_rouge([document.summary_sents], [c_string])\n",
    "    scores_pred.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1_f_scores_pred =[]\n",
    "for score in scores_pred:\n",
    "    f_score = score['rouge-1']['f'][0]\n",
    "    rouge1_f_scores_pred.append(f_score)\n",
    "\n",
    "# Find average rouge score for all documents in validation set\n",
    "model_score = sum(rouge1_f_scores_pred)/len(rouge1_f_scores_pred)\n",
    "\n",
    "print(\"Model's Rouge-1 F1 Score: {}\".format(model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Rouge-2 F1 Score: 0.14429496859829427\n"
     ]
    }
   ],
   "source": [
    "rouge2_f_scores_pred =[]\n",
    "for score in scores_pred:\n",
    "    f_score = score['rouge-2']['f'][0]\n",
    "    rouge2_f_scores_pred.append(f_score)\n",
    "\n",
    "# Find average rouge score for all documents in validation set\n",
    "model_score = sum(rouge2_f_scores_pred)/len(rouge2_f_scores_pred)\n",
    "\n",
    "print(\"Model's Rouge-2 F1 Score: {}\".format(model_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Rouge-2 F1 Score based off of our \"true\" y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_true = pd.Series(rouge_scores).iloc[indices][:val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see if Rouge-2 score averages match what we outputted in preprocessing\n",
    "rouge_pre_proc = []\n",
    "for i in rouge_true:\n",
    "    rouge_pre_proc.append(np.float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label's Rouge-2 F1 Score: 0.25884311878219274\n"
     ]
    }
   ],
   "source": [
    "true_score = sum(rouge_pre_proc)/len(rouge_pre_proc)\n",
    "\n",
    "print(\"True label's Rouge-2 F1 Score: {}\".format(true_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to make code mor legible later\n",
    "def score_one(comb, document):\n",
    "    c_string=[]\n",
    "    for idx in comb:\n",
    "        if idx < document.doc_len:\n",
    "            c_string.append(document.doc_sents[idx])\n",
    "    score = rouge.compute_rouge([document.summary_sents], [c_string])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_one(y_true_combos[0], docs2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True average rouge score for our entire training set \n",
    "Based off true y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to drop null, or y's will not align\n",
    "docs2 = load_data(df['token_ops'].drop(null_y), df['token_heads'].drop(null_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13430"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our document # and # of y labels match\n",
    "display(len(docs2))\n",
    "display(len(y_unproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_combos = []\n",
    "for doc in y_unproc:\n",
    "    if doc != 'None':\n",
    "        y_p = doc.strip('(),').split(', ')\n",
    "        y_tpl = tuple(map(int, y_p))\n",
    "        y_true_combos.append(y_tpl)\n",
    "    else:\n",
    "        y_true_combos.append((9999999,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_true=[]\n",
    "for comb, document in zip(y_true_combos, docs2):\n",
    "    c_string=[]\n",
    "    for idx in comb:\n",
    "        if idx < document.doc_len:\n",
    "            c_string.append(document.doc_sents[idx])\n",
    "    score = rouge.compute_rouge([document.summary_sents], [c_string])\n",
    "    scores_true.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average true score for entire dataset: 0.25657885279697557\n"
     ]
    }
   ],
   "source": [
    "rouge2_f_scores =[]\n",
    "for score in scores_true:\n",
    "    f_score = score['rouge-2']['f'][0]\n",
    "    rouge2_f_scores.append(f_score)\n",
    "    \n",
    "avg_true_score = sum(rouge2_f_scores)/len(rouge2_f_scores)\n",
    "print(\"The average true score for entire dataset: {}\".format(avg_true_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
