{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/qilongxin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import json\n",
    "import lzma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords  \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# pd.options.display.max_columns = 999\n",
    "# pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fucnction to remove \\n and HTML tags\n",
    "# function adapted from https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    text_divided = text.splitlines()\n",
    "    text_divided_clean = \" \".join(text_divided)\n",
    "    text_divided_clean = text_divided_clean.lower()\n",
    "    text_divided_clean = re.sub('\"','', text_divided_clean) # remove '\"'\n",
    "    text_divided_clean = re.sub(r\"'s\\b\",\"\",text_divided_clean) # remove ''s'\n",
    "    text_divided_clean = re.sub(\"[^a-zA-Z]\", \" \", text_divided_clean) # removes all strings that contains a non-letter\n",
    "    return text_divided_clean\n",
    "\n",
    "\n",
    "# setting up tokenizer\n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(state):\n",
    "    # reading json files\n",
    "    cases = []\n",
    "    with lzma.open(state + '/data/data.jsonl.xz', 'r') as jsonl_file:\n",
    "        for case in jsonl_file:\n",
    "            cases.append(json.loads(str(case, 'utf-8')))\n",
    "\n",
    "    df = pd.DataFrame(cases).sort_values('decision_date').reset_index(drop=True)\n",
    "    df['decision_date'] = pd.to_datetime(df['decision_date'])\n",
    "\n",
    "    # parsing data\n",
    "    storage = []\n",
    "    for i in range(df.shape[0]):\n",
    "        casebody_idx = df.columns.get_loc(\"casebody\")\n",
    "        judges = df.iloc[i,casebody_idx]['data']['judges']\n",
    "        attorneys = df.iloc[i,casebody_idx]['data']['attorneys']\n",
    "        headnotes = df.iloc[i,casebody_idx]['data']['head_matter']\n",
    "        if df.iloc[i,casebody_idx]['data']['opinions'] != []:\n",
    "            opinions = df.iloc[i,casebody_idx]['data']['opinions'][0]['text']\n",
    "\n",
    "        headnotes_clean = text_cleaner(headnotes)\n",
    "        opinions_clean = text_cleaner(opinions)\n",
    "\n",
    "        storage.append({'judges': judges,\n",
    "                        'attorneys': attorneys,\n",
    "                        'headnotes': headnotes_clean,\n",
    "                        'opinions': opinions_clean})\n",
    "    df_parsed = pd.DataFrame(storage)\n",
    "    df = df_parsed.merge(df, left_index=True, right_index=True)\n",
    "\n",
    "    # tokenizing headnotes and opinions\n",
    "#     df['headnotes'] = df['headnotes'].apply(lambda x: tokenizer.tokenize(x))\n",
    "#     df['opinions'] = df['opinions'].apply(lambda x: tokenizer.tokenize(x))\n",
    "    df['headnotes_num_tokens'] = [len(notes) for notes in df['headnotes']]\n",
    "    df['opinions_num_tokens'] = [len(opinions) for opinions in df['opinions']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = get_data('Arkansas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(summary)\n",
    "        output_lang = Lang(text)\n",
    "    else:\n",
    "        input_lang = Lang(text)\n",
    "        output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000 \n",
    "val_size = 200\n",
    "\n",
    "train = df_ar.sample(n=train_size,replace=False, random_state=1)\n",
    "val = df_ar.sample(n=val_size,replace=False, random_state=1)\n",
    "\n",
    "x_train,y_train = train.opinions.tolist(),train.headnotes.tolist()\n",
    "x_val,y_val = val['opinions'],val['headnotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 1000 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "0      the court overruled the motion  and said that ...\n",
      "1      this was an indictment for rape committed on t...\n",
      "2      opinion of the court  it is clear that the cou...\n",
      "3      opinion oe the court    the court below dismis...\n",
      "4      opinion of the court  the court below dismisse...\n",
      "5      johnson  j   delivered the opinion of the cour...\n",
      "6      opinion op the court   it is clear that the co...\n",
      "7      johnson  j  william russell sued out from two ...\n",
      "8      on motion of the prosecuting attorney  the cou...\n",
      "9      opinion oe the court    in this case it would ...\n",
      "10     opinion oe the court    in this case it would ...\n",
      "11     per curiam  after the commencement of a suit a...\n",
      "12     opinion op the court   daniel plott recovered ...\n",
      "13     opinion of the court  this is an action on the...\n",
      "14     opinion of the court  the only question we dee...\n",
      "15     opinion of the court  this is a case brought h...\n",
      "16     opinion op the court    this is a case brought...\n",
      "17     opinion op the court    this was an action of ...\n",
      "18     opinion oe the court    this is an action on t...\n",
      "19     opinion oe the court    daniel plott recovered...\n",
      "20     per curiam  after the commencement of a suit a...\n",
      "21     opinion of tiie court    the only question we ...\n",
      "22     opinion op the court    the only ground relied...\n",
      "23     opinion  of the court  the only ground relied ...\n",
      "24     opinion oe the court    the judgment in this c...\n",
      "25     opinion oe the court    this is a motion by th...\n",
      "26     opinion oe the court    this was an appeal fro...\n",
      "27     pee cukiam    the judgment in this case being ...\n",
      "28     per curiam  the judgment in this case being re...\n",
      "29     opinion of the court  this was an appeal from ...\n",
      "                             ...                        \n",
      "970    oldham  j  delivered the opinion of the court ...\n",
      "971    oldham  j   delivered the opinion of the court...\n",
      "972    j oiinson c  j   delivered the opinion of the ...\n",
      "973    cross  j  delivered the opinion of the court  ...\n",
      "974    oldham j   delivered the opinion of the court ...\n",
      "975    johnson  c  j   delivered the opinion of the c...\n",
      "976    johnson c  j   delivered the opinion of the co...\n",
      "977    opinion op the court    a judgment having been...\n",
      "978    johnson  c  j  it is contended by the appellan...\n",
      "979    joimsow  c  j  the question presented is wheth...\n",
      "980    joiinson  c  j  upon the state of facts as exh...\n",
      "981    oldham  j  this action is brought upon a coven...\n",
      "982    oiidhamj j  this case is brought into this cou...\n",
      "983    oldiiam  j  the object of the law in requiring...\n",
      "984    oldham  j  the declaration in this case is mos...\n",
      "985    johns pn     j  the plaintiff in error has rai...\n",
      "986    oldham  jl the defendants below moved to dismi...\n",
      "987    oidham  j  we do not deem it essential to the ...\n",
      "988    ckoss  j  in the collection of claims against ...\n",
      "989    cross  j  the judgment rendered in this ease b...\n",
      "990    johnson  o   j  the first five pleas interpose...\n",
      "991    oldham  j  it has frequently been decided that...\n",
      "992    oldham  j  the only question presented by the ...\n",
      "993    oldham  j  the main question presented by the ...\n",
      "994    ojudham  j  the first objection made by the pl...\n",
      "995    johnson  c  j  the plaintiffs in error insist ...\n",
      "996    opinion oe the court    this is a motion to di...\n",
      "997    oldham  j  the question presented in this case...\n",
      "998    oldham  j  it has frequently been decided by t...\n",
      "999    opinion oe the court    by act of congress  pa...\n",
      "Name: opinions, Length: 1000, dtype: object 15892\n",
      "0      case  no        a  united states v  dickinson ...\n",
      "1      the united states vs  thomas dickinson     it ...\n",
      "2      case no        a  thompson et al  v  campbell ...\n",
      "3      hewes scull vs  joseph kuykendall  a suit shou...\n",
      "4      case no        b  scull v  kuykendall   hempst...\n",
      "5      william russell vs  amos wheeler et al     in ...\n",
      "6      thompson and mathews vs  campbell     it is er...\n",
      "7      case no        a  russell v  wheeler et al   h...\n",
      "8      in the matter of radford ellis  a grand juror ...\n",
      "9      william neely vs  robinson et al  an attorney ...\n",
      "10     case no       a  in re ellis   hempst      sup...\n",
      "11     edward good vs  samuel davis     accord and sa...\n",
      "12     case uo       a  hodge v  plott   hempst      ...\n",
      "13     case no          blakely v  fish   hempst     ...\n",
      "14     case no       a  byington et al  v  lemmons   ...\n",
      "15     case no       a  jeffrey v  schlasinger et al ...\n",
      "16     jesse jeffrey  appellant  vs  schlasinger and ...\n",
      "17     benjamin murphy vs  thomas h  tindall  it is n...\n",
      "18     william blakely vs  david fish  an appeal will...\n",
      "19     arch hodge vs  daniel plott     in an appeal f...\n",
      "20     case no       a  good v  davis   hempst       ...\n",
      "21     e  byington and benjamin murphy vs  james lemm...\n",
      "22     william blakely  administrator of moses graham...\n",
      "23     case no          blakely v  ruddell   hempst  ...\n",
      "24     john wyatt  appellant  vs  jacob harden  appel...\n",
      "25     benjamin murphy vs  eli j  lewis and daniel mo...\n",
      "26     john taylor vs  edmund hogan  it is no ground ...\n",
      "27     case no       a  hogan v  taylor   hempst     ...\n",
      "28     edmund f  hogan vs  creed taylor  tlie judgmen...\n",
      "29     case no        a  taylor v  hogan     hempst  ...\n",
      "                             ...                        \n",
      "970    hawkins vs  campbell  the puffing of commoditi...\n",
      "971    lawson  adm r of trotter  use  c  vs  crutchfi...\n",
      "972    gabe alias santa anna vs  state  passing count...\n",
      "973    fowler vs  pearce  sheriff  c  the  judgment i...\n",
      "974    dickinson vs  noland  issues to pleas in abate...\n",
      "975    wise vs  yell  a judgment rendored by iho circ...\n",
      "976    cheadle vs  riddle  as to what is a substantia...\n",
      "977    the united states vs  the bank of the state of...\n",
      "978    duncan vs  ripley  by appearing and pleading i...\n",
      "979    wallace vs  state bank  the principal bank and...\n",
      "980    crawford county vs  wilson  county warrants is...\n",
      "981    cassady   dunn vs  clarke  plaintiff agreed to...\n",
      "982    trice vs  crittenden county  by tlie    chap  ...\n",
      "983    byrd  use   c  vs  crutchfield  the object of ...\n",
      "984    hammett et al  vs  state  use lindsay  in an a...\n",
      "985    patterson vs  the state  in criminal cases in ...\n",
      "986    hardwick et al  vs  campbell    co  motion to ...\n",
      "987    tarwater vs  davis  ex rx  d   by deed   barga...\n",
      "988    ryan et al  use  c  vs  lemon  as ad  in the c...\n",
      "989    jordan et al  vs  jennings   be points raised ...\n",
      "990    murphey vs  state bank   he bank of the state ...\n",
      "991    newton vs  tibbatts  the slate legislatures ha...\n",
      "992    robinson vs  the state  there being no palpabl...\n",
      "993    ross vs  turner et al  ads  use  c  covenants ...\n",
      "994    dillard s ad r vs  moore  in cases where appea...\n",
      "995    semon et al  vs  hill  as administrator  in de...\n",
      "996    charles t  nelson  complainant  vs  winslow ro...\n",
      "997    gibson vs  emerson  the    sec  of  an act to ...\n",
      "998    mayers vs  the state   this court will not int...\n",
      "999    the united states vs  ellis starr     until th...\n",
      "Name: headnotes, Length: 1000, dtype: object 20465\n",
      "['johnson  j  this is an action of trespass for an assault and battery  brought by jeffries against  william b   marshall  marshall pleaded a misnomer of the plaintiff named  alleging that he was called and known by the name of jesse jeffery  and not by the name of jesse jeffries  to this plea jeffries demurred  and the demurrer was sustained  the only question for the consideration of this court  relates to the decision on the demurrer to the plea in abatement  we think the court erred in sustaining the demurrer to that plea  we do not think that jeffery and jeffries are the same name  they are differently spelt  and clearly cannot be said to be idem sonans  the judgment must be reversed  and the cause remanded  with directions to permit the defendant in error to reply to the plea of misnomer  if he shall apply for leave to do so  and on his failure  then to give judgment in accordance with the plea in abatement  reversed ', 'case no       a  marshall v  jeffries   hempst        superior court  territory of arkansas  feb         pleading at law   misnomer idem sonans   jeffery  and  jeffries  are not idem sonans  error to lawrence circuit court  before johnson and yell  jj ']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData( x, y , False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    if input_length > max_length:\n",
    "        length = max_length\n",
    "    else:\n",
    "        length = input_length\n",
    "        \n",
    "    for ei in range(length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    print(\"Training....\")\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if iter% 1000 == 0:\n",
    "            print(iter,\"/\",n_iters + 1)\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        \n",
    "        if input_length > max_length:\n",
    "            length = max_length\n",
    "        else:\n",
    "            length = input_length\n",
    "        \n",
    "        for ei in range(length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=1):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "0m 0s (- 0m 6s) (1 10%) 9.9147\n",
      "1m 30s (- 6m 0s) (2 20%) 9.8303\n",
      "1m 59s (- 4m 38s) (3 30%) 68.3030\n",
      "2m 2s (- 3m 3s) (4 40%) 257.8905\n",
      "2m 20s (- 2m 20s) (5 50%) 114.6407\n",
      "2m 27s (- 1m 38s) (6 60%) 74.2404\n",
      "2m 48s (- 1m 12s) (7 70%) 96.5427\n",
      "3m 0s (- 0m 45s) (8 80%) 208.3252\n",
      "3m 5s (- 0m 20s) (9 90%) 301.8702\n",
      "3m 31s (- 0m 0s) (10 100%) 209.3794\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 10, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), './enc.w')\n",
    "torch.save(attn_decoder1.state_dict(), './att.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dickinson j   delivered the opinion of the court  section    of the rev  stat  ark  under the title  execution  p       authorizes the sheriff to permit the defendant in execution  to retain possession of the property levied upon  by giving bond in favor of the plaintiff with sufficient security  in double the value of such property  conditioned for the delivery of the property to the officer at the time and place of sale to be named in such condition   and by the provisions of the   th section of the same act   if the condition of the bond be broken  and the execution be returned unsatisfied  the defendants and his securities shall be  deemed to have notice of the facts  and the plaintiff  without further notice  may on the relurri day of the execution  or on any subsequent day of the term at which such execution is returned  move the court for judgment on the bond against the defendant and his sureties  or any of them  or the plaintiff may at his option bring an ordinary suit on the bond   the   st section  which was in force in may        but had been repealed previous to january         provided that   if any controversy arise on the motion  it shall be heard and determined in a summary manner  without the form of pleading  and unless the demand be avoided  judgment shall be rendered thereon without delay  according to the circumstances   the language of the statute is plain and imperative  if the defendant in error intended to avail himself of the remedy afforded by motion  and bring himself within its provisions  he must conform strictly to all its requisites  if he fails or neg lects so to do  at the return term of the execution  he unquestionably by his laches  waives any advantage and forfeits every right he may have had to relief under that mode of proceeding  in the transcript before us  no such motion appears to have been made until the january term following  that the court erred in taking cognizance of the motion  and in rendering judgment thereon against the plaintiffs in error  there can be no question or doubt  the judgment of the circuit court of chicot county must therefore be reversed  annulled  and set aside with costs \n",
      "= webb   taylor against brown  eekoe to chicot circuit court  the statute which authorizes judgment on motion upon a forfeited delivery bond  authorizes such judgment only at the term at which the execution is returned  and a judgment rendered at any subsequent term is void  brown obtained judgment against webb at the november term of the chicot circuit court        and n the   th of january        had a writ o f fieri facias issued upon the judgment returnable to the may term        which was placed in the hands of the sheriff  and on the   d of april  was levied upon several of webb s negroes  on the day of the levy  webb  and taylor as his security  executed their bond  to the plaintiff  brown  conditioned for the forthcoming and delivery of the negroes on the   th day of may        the first day of the circuit court  on the   th day of may  the sheriff returned the execution unsatisfied  and endorsed the failure of webb and taylor to deliver the negroes according to the condition of the bond  on the   th day of january        and at a term of the court subsequent to that in which the execution was returned and returnable  brown  the defendant in error  moved the court to renderjudgment upon the bond  under the   th section of the statute of executions  which motion  although resisted by the plaintiffs in error  was sustained by the court  and judgment rendered for the amount of the original judgment  and ten per cent  damages and the defendants excepted  teapnall   cocke  for the plaintiffs  the   th section of the statute  under which this motion was made  provides that  if the condition of the bond be broken  and the execution be returned unsatisfied  the defendant and his securities shall be deemed to have notice of the facts  and the plaintiff without further notice may  on the return day of the execution  or on any subsequent day of the term  at which such execution is returned  move the court for a judgment on the bond  against the defendant and his securities or any of them  or the plaintiff may at his option bring an ordinary suit on the bond  the legislature have expressed in this section  with so much distinctness  that the summary remedy  by motion on the bond  and notice thereof to the defendants  was to be confined to the return day of the execution  or any subsequent day of the term  at which such execution was returned  as to cut off all necessity or apology for argument or array of authorities  e  l  johnson  contra  submitted this case without argument \n",
      "< in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "rouge = rouge.Rouge()\n",
    "\n",
    "def getRougeScore(encoder, decoder, n=10):\n",
    "    scores = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        sc = rouge.get_scores(output_sentence, pair[1])\n",
    "        scores[i] = sc[0]['rouge-1']['f']\n",
    "    return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03571428, 0.03179916, 0.04423748, 0.0530303 , 0.        ,\n",
       "       0.03789127, 0.02886598, 0.02443281, 0.04910714, 0.01204819,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRougeScore(encoder1,attn_decoder1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
